\begin{rem}
 An inner product, allows us to ``measure'' angles between vectors.
\end{rem}
\section[Differentiability]{Differentiability; linear maps, matrices and the operator norm}
\begin{defn}
 Let $\Set{X}$, $\Set{Y}$ be two vector spaces over $\RR$. A map $A:\Set{X}\to\Set{Y}$ is called linear iff $A(\alpha x+\beta y)=\alpha A(x)+\beta A(x)\qquad \forall \alpha, \beta\in\RR, \forall x,y\in\Set{X}$. The set of linear maps $\Set{X}\to\Set{Y}$ is denoted by $L(\Set{X}, \Set{Y})$. $L(\Set{X},\Set{X})$ is denoted $L(\Set{X})$. Often we write $A\ x$ instead of $A(x)$. 
\end{defn}
\subsection*{Facts:}
\begin{enumerate}
 \item $A\:0=0\qquad\forall A\in L(\Set{X}, \Set{Y})$. 
 \item If $\Set{X}$ is finite dimensional (e.g. $\RR^n$), then $A\in L(\Set{X})$ bijective $\Leftrightarrow A$ injective $\Leftrightarrow$ A surjective.
 \begin{proof}[Proof Sketch]
  $A$ surjective $\Leftrightarrow \card{A \Set{X}}=\card{\Set{X}}\Leftrightarrow \card{A^{-1} \Set{X}}=\card{\Set{X}}\Leftrightarrow A$ injective (by linearity). 
 \end{proof}
 \item $\forall A_1, A_2\in L(\Set{X},\Set{Y}), \:\forall\alpha_1, \alpha_2\in\RR:$
 $$(\alpha_1 A_1+\alpha_2 A_2)\in L(\Set{X}, \Set{Y}).$$
 Thus $L(\Set{X},\Set{Y})$ is a vector space.
\end{enumerate}
\begin{defn}
 The set $\Set{M}^{m\x n}(\RR)$ of $(m\x n)$-matrices $\forall m,n\in\NN$ fixed consists of all vectors in $\RR{m\cdot n}$ written in a ``separable form'' i.e. $$A:=(a_{i,j})\begin{matrix}1\leq i\leq n\\1\leq j\leq m\end{matrix}=:\left(\begin{matrix}a_{1,1}, a_{1,2},\ldots, a_{1,n}\\a_{2,1}, a_{2,2},\ldots, a_{2,n}\\\vdots\\ a_{m,1}, a_{m,2},\ldots, a_{m,n}\end{matrix}\right).$$
\end{defn}
\begin{defn}
 Matrix multiplication is defined by:
 Let $A\in\RLinSpaNM{n}{m}, B\in\RLinSpaNM{m}{p}$. Then $C:= A\cdot B:=(c_{k,j})\begin{matrix}1\leq j\leq n\\1\leq k\leq p\end{matrix}$, where $c_{k,j}=\sum_{i=1}^{m}a_{i,j}b_{k,i}\in\RLinSpaNM{n}{p}$. Furthermore, $A\in\RLinSpaNM{m}{n}$ is called invertible iff $\exists A^{-1}\in\RLinSpaNM{n}{m}$. $AA^{-1}=A^{-1}A=I_n:=\left(\begin{matrix}1\ 0\ 0\ \ldots 0\\0\ 1\ 0\ 0\ldots\\\vdots\\0\ 0\ \ldots 0\ 1\end{matrix}\right)$ ($\Rightarrow m=n$), where $I_n$ is the identity matrix.
\end{defn}
\begin{rem}
 Matrix multiplication is not commutative (only associative, as is function composition in general).
\end{rem}
\begin{rem}
 $\Set{M}^{m\x n}$ is a vector space over $\RR$ for all $m,n\in\NN$.
\end{rem}
\begin{enumerate}
 \item[4.] Let $\Set{X}, \Set{Y}$ be finite dimensional vector spaces with basis $\{\fseq{x}{n}\}, \linebreak[4]\{\fseq{y}{m}\}$. We can now use these basis to define the natural isomorphism between $\Set{M}^{m\x n}$ and \[L(\Set{X},\Set{Y}): A_{i,j}\to \left((x_k)_{k\in\upto{n}}\to \left(\sum_{k=1}^{m}a_{i,k}\right)_{i\in\upto{n}}\right).\] By linearity and item (2) we see that this mapping is a linear bijection, thus it is an isomorphism. 
 Sometimes we will denote the matrix associated to an linear map (given a fixed basis) $A$ by $[A]$. Usually we will not distinguish between $A$ and $[A]$. 
 \item[5.] Let $A\in L(\Set{X},\Set{Y}), B\in L(\Set{Y},\Set{Z})$ be linear maps, then $B\circ A\in L(\Set{X},\Set{Z})$ and $[B\circ A]=[B]\cdot[A]$.
 \item[6.] $A\in L(\Set{X})$ inveritble $\Leftrightarrow [A]$ invertible (under multiplication) $\Leftrightarrow\det(A)\neq 0$. 
\end{enumerate}
\begin{rem}
	$\Set{M}^{m\x n}$ is topologically just $\RR{m\cdot n}$. 
\end{rem}
\begin{defn}[operator norm]
 For $A\in L(\Set{X},\Set{Y})$, define the operator norm by $\Norm{A}:=\sup_{\Norm{x}\leq 1}\Norm{A x}$.
\end{defn}
\begin{rem}
 operator norm not isometric to $\Norm{\cdot}_2$.
\end{rem}
\begin{lem}
 \label{lem:obvbndOpNorm}
 If $\alpha\in\RR$ has the property that $\Norm{A x}\leq \Norm{x_i}\:\forall x\in\RR^n$, then $\Norm{A}\leq \alpha$.
\end{lem}
\begin{proof}
 $\forall x\in\RR^n,\:\Norm{u}\leq 1$, we have that $\Norm{Au}\leq \alpha\Norm{u}\leq\alpha$. Thus, by definition of the operator norm $\Norm{A}=\sup_{\Norm{u}\leq 1}\Norm{Au}\leq \alpha$.
\end{proof}
\begin{thm}[Properties of the operator norm]
 \begin{enumerate}
  \item $\Norm{Ax}\leq\Norm{A}\Norm{x}, \:\forall\in L(\RR, \RR^n)\ \forall x\in\RR^n$.
  \item $\Norm{A}<\infty,\qquad\forall A\in L(\RR^n,\RR^m)$.
  \item $\forall A\in L(\RR^n, \RR^m).\:A$ Lipschitz i.e. $\exists$ a real constant (here the operator norm) s.t. $\Norm{Ax-Ay}\leq\Norm{A}\Norm{x-y}, \:\forall x,y\in\RR^n$.
  \begin{exc}
   This implies uniform continuity.
  \end{exc}
  \item The operator norm is a norm i.e. $\forall A, B\in L(\RR^n,\RR^m), \forall \alpha\in\RR$, we have:
  \begin{enumerate}
   \item $\Norm{A+B}\leq \Norm{A}+\Norm{B}$, the triangular inequality
   \item $\Norm{\alpha A}=\abs{\alpha}\Norm{A}$
  \end{enumerate}
  \item $\forall A, B\in L(\RR^n, \RR^m).\:\Norm{BA}\leq \Norm{B}\Norm{A}$.
  \item With $I(\RR^n)\subset L(\RR^n):=\{A\in L(\RR^n)\text{ invertible}\}$ we have that for $A\in I(\RR^n)$, $B\in L(\RR^n)$ and $\Norm{B-a}\Norm{A^{-1}}<1$ it follows $B\in I(\RR^n)$. 
  In other words, $\forall A\in I(\RR)$, we have that $\Ball{A}{\frac{1}{\Norm{A^{-1}}}}\subset I(\RR^n)$. Thus, $I(\RR^n)$ is open in $\RR^n$.
  \item $\forall A\in I(\RR^n).\:A^{-1}$ is continuous. 
 \end{enumerate}
\end{thm}
\begin{proof}\ 
 \begin{enumerate}
  \item Fix $x\in\RR, x\neq 0$ then for $\frac{x}{\Norm{x}}$ we obtain $\Norm{\frac{x}{\Norm{x}}}=\frac{1}{\Norm{x}}\Norm{x}=1$. 
  By definition $\Norm{A}\geq \Norm{A\left(\frac{x}{\Norm{x}}\right)}=\frac{1}{\Norm{x}}\Norm{A(x)}\Rightarrow\Norm{A}\Norm{x}\geq\Norm{A}$. The case $x=0$ is trivial. 
  \item $\forall A\in L(\RR^m, \RR^n).\:\Norm{A}\leq m\cdot n\cdot \max(A)<\infty$.
  \item Follows from linearity and item 2.
  \item \begin{enumerate}
   \item Obvious.
   \item By linearity (preserved by $\sup$)
  \end{enumerate}
  \item By item 1 and Lemma \ref{lem:obvbndOpNorm}:
  \begin{equation}
   \label{eqn:bndCompOpNorm}
   \Norm{BAx}\leq \Norm{BA}\Norm{x}\leq \Norm{B}\Norm{A}\Norm{x}
  \end{equation}
  \item Using item 1 and linearity:
  \begin{align*}
   &\frac{\Norm{x}}{\Norm{A^{-1}}}=\frac{\Norm{A^{-1}Ax}}{\Norm{A^{-1}}}\overset{\text{item 1}}{\leq}\frac{\Norm{A^{-1}}}{\Norm{A^{-1}}}\Norm{Ax}=\Norm{Ax}\\
   =&\Norm{(A-B)x+Bx}\overset{\text{item 4}}{\leq}\Norm{A-B}\Norm{x}+\Norm{Bx}
  \end{align*}
  Therefore by assumption $0<\frac{1}{\Norm{A^{-1}}}\Norm{x}\leq\Norm{Bx}$.
  Thus, $x\neq 0\Rightarrow 0<\Norm{Bx}\Rightarrow B$ invertible. 
  \item By item 5 and item 6: $\Norm{BA}\leq\Norm{B}\Norm{A}$.  
 \end{enumerate}
\end{proof}
\begin{lem}
	$\Norm{A}=0\Rightarrow A$ not invertible.
\end{lem}
\begin{proof}
	Assume $\Norm{A}=0\Rightarrow \forall x\in\RR^n.\:0=\Norm{A}\Norm{x}\geq \Norm{Ax}\Rightarrow\Norm{Ax}=0$. Thus $A$ is not invertible at all.
\end{proof}
